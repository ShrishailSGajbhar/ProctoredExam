{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def compare_faces(sourceFile, targetFile):\n",
    "\n",
    "    client=boto3.client('rekognition',region_name='ap-south-1',aws_access_key_id=\"AKIASYFWYYMEGJOJ2AAZ\",aws_secret_access_key=\"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\")\n",
    "   \n",
    "    imageSource=open(sourceFile,'rb')\n",
    "    imageTarget=open(targetFile,'rb')\n",
    "\n",
    "    response=client.compare_faces(SimilarityThreshold=80,\n",
    "                                  SourceImage={'Bytes': imageSource.read()},\n",
    "                                  TargetImage={'Bytes': imageTarget.read()})\n",
    "    \n",
    "    for faceMatch in response['FaceMatches']:\n",
    "        position = faceMatch['Face']['BoundingBox']\n",
    "        similarity = str(faceMatch['Similarity'])\n",
    "        print('The face at ' +\n",
    "               str(position['Left']) + ' ' +\n",
    "               str(position['Top']) +\n",
    "               ' matches with ' + similarity + '% confidence')\n",
    "\n",
    "    imageSource.close()\n",
    "    imageTarget.close()     \n",
    "    return len(response['FaceMatches'])          \n",
    "\n",
    "def main():\n",
    "    source_file='s1.jpg'\n",
    "    target_file='s2.jpg'\n",
    "    face_matches=compare_faces(source_file, target_file)\n",
    "    print(\"Face matches: \" + str(face_matches))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def detect_faces(photo):\n",
    "\n",
    "    client=boto3.client('rekognition',region_name='ap-south-1',aws_access_key_id=\"AKIASYFWYYMEGJOJ2AAZ\",aws_secret_access_key=\"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\")\n",
    "    imageSource=open(photo,'rb')\n",
    "    response = client.detect_faces(Image={'Bytes': imageSource.read()},Attributes=['ALL'])\n",
    "    return len(response['FaceDetails'])\n",
    "\n",
    "def main():\n",
    "    photo='download.jpg'\n",
    "    face_count=detect_faces(photo)\n",
    "    print(\"Faces detected: \" + str(face_count))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import boto3\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "cap = cv.VideoCapture(0)\n",
    "def detect_faces(photo):\n",
    "\n",
    "    client=boto3.client('rekognition',region_name='ap-south-1',aws_access_key_id=\"AKIASYFWYYMEGJOJ2AAZ\",aws_secret_access_key=\"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\")\n",
    "    #imageSource=open(photo,'rb')\n",
    "    response = client.detect_faces(Image={'Bytes': photo},Attributes=['ALL'])\n",
    "    return len(response['FaceDetails'])\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', gray)\n",
    "    pil_img = Image.fromarray(frame) # convert opencv frame (with type()==numpy) into PIL Image\n",
    "    stream = io.BytesIO()\n",
    "    pil_img.save(stream, format='JPEG') # convert PIL Image to Bytes\n",
    "    bin_img = stream.getvalue()\n",
    "    face_count=detect_faces(bin_img)\n",
    "    print(\"Faces detected: \" + str(face_count))\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surprised-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Furniture\n",
      "----------\n",
      "Label: Mouse\n",
      "----------\n",
      "Label: Hardware\n",
      "----------\n",
      "Label: Computer\n",
      "----------\n",
      "Label: Electronics\n",
      "----------\n",
      "Label: Table\n",
      "----------\n",
      "Label: Desk\n",
      "----------\n",
      "Label: Monitor\n",
      "----------\n",
      "Label: Display\n",
      "----------\n",
      "Label: Screen\n",
      "----------\n",
      "Label: Computer Keyboard\n",
      "----------\n",
      "Label: Keyboard\n",
      "----------\n",
      "Label: Computer Hardware\n",
      "----------\n",
      "Label: Mobile Phone\n",
      "----------\n",
      "Label: Phone\n",
      "----------\n",
      "Label: Cell Phone\n",
      "----------\n",
      "Label: Person\n",
      "----------\n",
      "Label: Human\n",
      "----------\n",
      "Label: Clock Tower\n",
      "----------\n",
      "Label: Building\n",
      "----------\n",
      "Label: Architecture\n",
      "----------\n",
      "Label: Tower\n",
      "----------\n",
      "Label: LCD Screen\n",
      "----------\n",
      "Labels detected: 23\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "def detect_labels(photo):\n",
    "\n",
    "    client=boto3.client('rekognition',region_name='ap-south-1',aws_access_key_id=\"AKIASYFWYYMEGJOJ2AAZ\",aws_secret_access_key=\"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\")\n",
    "    \n",
    "    imageSource=open(photo,'rb')\n",
    "    response = client.detect_labels(Image={'Bytes': imageSource.read()})\n",
    "      \n",
    "    for label in response['Labels']:\n",
    "        print (\"Label: \" + label['Name'])\n",
    "        print (\"----------\")\n",
    "        \n",
    "    return len(response['Labels'])\n",
    "\n",
    "def main():\n",
    "    photo='desk.jpg'\n",
    "    label_count=detect_labels(photo)\n",
    "    print(\"Labels detected: \" + str(label_count))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-packing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286ffff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
